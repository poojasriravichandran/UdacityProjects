import sys
import nltk
import numpy as np
import pandas as pd
from typing import Tuple, List
from sqlalchemy import create_engine
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.model_selection import GridSearchCV
from sklearn.multioutput import MultiOutputClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import fbeta_score, make_scorer, accuracy_score
from sklearn.metrics import classification_report
nltk.download('punkt')
nltk.download('wordnet')
import pickle

def load_data(database_filepath: str)->Tuple[pd.DataFrame, pd.DataFrame, List[str]]:
    '''
    Function for loading the database into pandas DataFrames
    Args: database_filepath: the path of the database
    Returns:    X: features (messages)
                y: categories (one-hot encoded)
                An ordered list of categories
    '''
    # Loading the database into a pandas DataFrame
    engine = create_engine('sqlite:///{}'.format(database_filepath))
    df = pd.read_sql("SELECT * FROM disaster_response",engine) 
def tokenize(text:str)->List[str] :
    '''
    Function for tokenizing string
    Args: Text string
    Returns: List of tokens
    '''
    tokens = nltk.word_tokenize(text)
    lemmatizer = nltk.WordNetLemmatizer()
def build_model()->GridSearchCV:
    '''
    Function for building pipeline and GridSearch
    Args: None
    Returns: Model
    '''
    # Pipeline for transforming data, fitting to model and predicting
    pipeline = Pipeline([
        ('vect', CountVectorizer(tokenizer=tokenize)),
        ('tfidf', TfidfTransformer()),
        ('clf', RandomForestClassifier())])
def evaluate_model(model: GridSearchCV, X_test: pd.DataFrame, Y_test: pd.DataFrame, category_names: List)->None:
    '''
    Function for evaluating model by printing a classification report
    Args:   Model, features, labels to evaluate, and a list of categories
    Returns: Classification report
    '''
    y_pred = model.predict(X_test)
    print(classification_report(Y_test, y_pred, target_names=category_names))
    for  idx, cat in enumerate(Y_test.columns.values):
        print("{} -- {}".format(cat, accuracy_score(Y_test.values[:,idx], y_pred[:, idx])))
    print("accuracy = {}".format(accuracy_score(Y_test, y_pred)))
def save_model(model: GridSearchCV, model_filepath: str)-> None:
    '''
    Function for saving the model as picklefile
    Args: Model, filepath
    Returns: Nothing. Saves model to pickle file
    '''
    with open(model_filepath, 'wb') as file:  
        pickle.dump(model, file)
def main():
    if len(sys.argv) == 3:
        database_filepath, model_filepath = sys.argv[1:]
        print('Loading data...\n    DATABASE: {}'.format(database_filepath))
        X, Y, category_names = load_data(database_filepath)
        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)
   if __name__ == '__main__':
    main()
